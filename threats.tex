\section{Threats to validity}
\label{section_threats}

This section presents the threats to validity of our empirical study.

%%%------------------------------------------------------------------------------------------
\subsection{Internal threats}

Internal validity refers to the fact that our findings truly represent a cause-and-effect relationship and, therefore, the internal validity of our study focuses on the implementation of our experiments.

The probabilistic extension - of the denotational semantics - presented in this paper has been implemented by two experts. The source code has been studied and checked by two additional - advanced - programmers. Although we have performed a careful testing and analysis process of the source code, we cannot assure the total absence of errors. This source code is available at \url{http://ccamacho.github.io/phd/resources/03_splap.tar}

The feature models used in the experiments have been generated by using BeTTy~\cite{sg12}, which is a widely used tool in the scientific community. Thus, we assume this tool correct to carry out the experiments.

Other issues might arise due to the random nature of the generated feature models. In order to mitigate this issue, a statistical analysis have been performed to study the variability of the results, where 10 different features models have been generated. In this case, all the generated feature models provide similar performance results.

%%%------------------------------------------------------------------------------------------
\subsection{External threats}

External validity concerns the extent to which the results of a study can be generalized.

We have used 4 different configurations to generate feature models in our empirical study (1 for Section \ref{sec:stat:impl:model:analysis} and 3 for Section \ref{sec:stat:impl:performance:analysis}).
Also, for each configuration we have been generated 11 different models for Section \ref{sec:stat:impl:model:analysis} and 30 for Section \ref{sec:stat:impl:performance:analysis} - per number of features -. In essence, we are interested in investigating the overall performance of our implementation. Since features involved in a \textit{Conjunction} relationship require more computing time to be processed, the idea is to increase the probability of having a \textit{Conjunction} relationship in the models, like is described in Table \ref{scalaExperiment}. Hence, although we believe that these models are representative for our empirical study, we cannot guarantee that the same results are obtained for other scenarios.


%%%------------------------------------------------------------------------------------------
\subsection{Constructs threats}

Construct validity concerns whether the used measures are representative or not.

We measured the overall performance of our approach based on the execution time and memory consumption,
which are widely used in the community. All the experiments have been carried out using the same computing node described in Section \ref{sec:stat:impl}.



